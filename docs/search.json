[
  {
    "objectID": "IDPs.html",
    "href": "IDPs.html",
    "title": "IDPs",
    "section": "",
    "text": "This mini-project analyzes the number of Internally Displaced People (IDPs) in 2020 in countries which had more than 500000 of them. Data is provided by the TidyTuesday library, which compiled the data from multiple UN agencies and the the Internal Displacement Monitoring Centre (IDMC).\n\nlibrary(tidyverse)\nlibrary(tidytuesdayR)\nlibrary(ggplot2)\ntuesdata &lt;- tidytuesdayR::tt_load('2023-08-22')\npopulation &lt;- tuesdata$population\n\nfilterdata &lt;- population |&gt;\n  filter(idps &gt;= 500000, year == 2020)\n\nggplot(filterdata, aes(x = reorder(coo_name, idps), y = idps)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Number of Internally Displaced People per Country in 2020\",\n       subtitle = \"A comparison of IDPs over 500,000 people per country in 2020\",\n       x = \"Country\", \n       y = \"Number of IDPs\") +\n  theme_gray() + coord_flip()\n\n\n\n\n\n\n\n\nAbove is a graph showing different numbers for IDPs (Internally Displaced Peoples) in 2020 across the countries with the highest numbers and a minimum of 500000 IDPs. We can see many countries which have a big refugee exflux to other countries (such as Syria and Afghanistan) are in the list, but more commonly we can see countries with internal conflicts which are not presently at the scale of a civil war. We can also see countries fighting others, such as in the case for Ukraine and Azerbaijan. Some root causes for IDPs include internal and external war as stated, but also include food shortages, local violence, water shortage, climate change, past wars’ effects, government change, and others. The data set originally includes other information, such as origin countries of refugees, their destination countries, etc.\nSources:\nTidyTuesday Source: https://github.com/rfordatascience/tidytuesday/blob/main/data/2023/2023-08-22/readme.md\nThe Original Source of the Data: The TidyTuesday dataset does not provide specific links to its data sources, but the most precise sources they mention are as following: “Data from UNHCR’s annual statistical activities dating back to 1951. Data from the United Nations Relief and Works Agency for Palestine Refugees in the Near East (UNRWA), specifically for registered Palestine refugees under UNRWA’s mandate. Data from the Internal Displacement Monitoring Centre (IDMC) on people displaced within their country due to conflict or violence.”"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Data Viz",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Uras Uyal",
    "section": "",
    "text": "Welcome to Uras Uyal’s website! Uras is a Freshman at Pomona College intending to major in Mathematics and Computer Science, and considering a minor in either Data Science or Physics. He is also interested in Geography, History, and Music as side hobbies."
  },
  {
    "objectID": "SpaceObjects.html",
    "href": "SpaceObjects.html",
    "title": "Objects in Space",
    "section": "",
    "text": "This mini-project analyzes trends in number of objects Russia and China have launched into space since 1957. Data is provided by the TidyTuesday library, which accessed the specific dataset from the United Nations Office for Outer Space Affairs (2024) helped by Our World in Data.\n\nlibrary(tidyverse)\nlibrary(tidytuesdayR)\nlibrary(ggplot2)\ntuesdata &lt;- tidytuesdayR::tt_load('2024-04-23')\nouter_space_objects &lt;- tuesdata$outer_space_objects\n\n\nouter_space_objects_filtered &lt;- filter(outer_space_objects, Entity == \"China\" | Entity == \"Russia\")\n                                       \nggplot(outer_space_objects_filtered, aes(x = Year, y = num_objects, color = Entity)) +\n  geom_line(size = 1) + \n  geom_point(size = 2) +  \n  labs(title = \"Number of Space Objects Launched by China vs. that of Russia\",\n       subtitle = \"A comparison of space activity since the 1950s\",\n       x = \"Year\", \n       y = \"Number of Space Objects Launched\",\n       color = \"Country\",\n       shape = \"Country\") +\n  theme_gray()\n\n\n\n\n\n\n\n\nAbove is a graph of number of objects sent into space by China vs. Russia from 1957 until 2023. Between the 1960s and 2000s, Russia was quite successful in their space launches, however, through the end of this timeframe, their space launches per year started to decrease. The rise in their space launches coincided with the Cold War, and the decline coincided with the dissolution of the Soviet Union in the early 1990s. We can see that in the 1950s and 1960s, China sent no objects into space but as mass education and technology developed in China, it was gradually be able to send objects into space, taking over the lead from Russia in the mid-2010s. Russia’s rise from the 1960s to the 1980s looks sort of logistical, whereas China’s rise since the 1990s looks more exponential, however, it is too early to decide. The causes of these could be the major reasons behind space launches: militaristic and governmental reasons vs. more commercial oriented government backed reasons in Russia and China’s cases respectively. The data set originally includes other countries and organizations around the world as well.\nSources:\nTidyTuesday source: https://github.com/rfordatascience/tidytuesday/blob/main/data/2024/2024-04-23/readme.md\nData Page: Annual number of objects launched into space”, part of the following publication: Edouard Mathieu and Max Roser (2022) - “Space Exploration and Satellites”. Data adapted from United Nations Office for Outer Space Affairs. Retrieved from https://ourworldindata.org/grapher/yearly-number-of-objects-launched-into-outer-space\nDataset: United Nations Office for Outer Space Affairs (2024) – with major processing by Our World in Data. “Annual number of objects launched into space – UNOOSA” [dataset]. United Nations Office for Outer Space Affairs, “Online Index of Objects Launched into Outer Space” [original data]. Retrieved April 21, 2024 from https://ourworldindata.org/grapher/yearly-number-of-objects-launched-into-outer-space"
  },
  {
    "objectID": "SongsAnalyis.html",
    "href": "SongsAnalyis.html",
    "title": "Songs Text Analysis",
    "section": "",
    "text": "{r}´´´ tuesdata &lt;- tidytuesdayR::tt_load(‘2020-01-21’) tuesdata &lt;- tidytuesdayR::tt_load(2020, week = 4) spotify_songs &lt;- tuesdata$spotify_songs"
  },
  {
    "objectID": "SongsAnalysis.html",
    "href": "SongsAnalysis.html",
    "title": "Songs Text Analysis",
    "section": "",
    "text": "We will be analyzing a data set of Spotify songs up to 2020. The data set source can be found at the very bottom of the page. We will be looking at trends in how many songs there is expected to be in a given album depending on genre, and will be analyzing how song titles changed over the decades. To start, we import our data.\n\n\nShow source code\ntuesdata &lt;- tidytuesdayR::tt_load('2020-01-21')\ntuesdata &lt;- tidytuesdayR::tt_load(2020, week = 4)\nspotify_songs &lt;- tuesdata$spotify_songs\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(dplyr)\n\n\n\nLooking at trends of the expected number of songs per album\nFirst, let’s take a look at the average number of songs per album. A lot of artists put up “singles”; so, in order to remove them, we filter for number of songs over 1 per album. Oftentimes, the most mainstream albums come with 7 to 12 or 13 songs per album. However, the data shows that less number of songs is more common for albums. The most common instance is 2 songs per album, then 3, etc.. This could be caused by smaller artists also being featured on Spotify and them having usually no restriction on a minimum amount of songs per album, or having any concern to release a bunch of songs at one time (they can do this over time). We see that all genres are not too extremely off from each other in songs per album; however, we see noticeable differences. Where EDM has about 2.42 songs per album, rap has 3.15. This may possibly be caused by the more vibrant and less-lyrics based nature of EDM opposed to the lyrics-heavy nature of rap. Lack of lyrics may possibly constitute in having less songs in a given album as it is harder to produce unique music with the element of just electronic music and the absence of words. EDM also tends to have the highest number of covers out of any genre as it is easier to mix-match, partly due to its relative lack of lyrics and technological produce again; where covers are only popular with popular songs, automatically making less-popular songs less covered, meaning less songs per a given album.\n\n\nShow source code\navg_songs_per_album &lt;- spotify_songs |&gt;\n  group_by(playlist_genre, track_album_id) |&gt;\n  summarise(songs_per_album = n()) |&gt;\n  group_by(playlist_genre) |&gt;\n  filter(songs_per_album &gt; 1) |&gt;\n  summarise(avg_songs_per_album = mean(songs_per_album))\nprint(avg_songs_per_album)\n\n\n# A tibble: 6 × 2\n  playlist_genre avg_songs_per_album\n  &lt;chr&gt;                        &lt;dbl&gt;\n1 edm                           2.42\n2 latin                         2.82\n3 pop                           2.76\n4 r&b                           3.09\n5 rap                           3.16\n6 rock                          2.95\n\n\nNow, let’s plot the number of songs per album and their instances detailing genres. What this graph tells us different to the data table above is the quickness in decrease of number of instances as number of songs per album increases. Expectedly, EDM, with the red bars, decreases quite fast compared to other genders as we go more right on the x-axis. Rap has quite a slower decreasing curve. Perhaps another color one might catch is orange, which constitutes to R&B, having quite a close curve to that of rap. If we look at our data table above, we see that R&B has a value that is quite close to rap, which fulfills our expectations.\n\n\nShow source code\nsongs_per_album_per_genre &lt;- spotify_songs |&gt;\n  group_by(playlist_genre, track_album_id) |&gt;\n  summarise(songs_per_album = n()) |&gt;\n  filter(songs_per_album &gt; 1)\n\nggplot(songs_per_album_per_genre, aes(x = songs_per_album, fill = playlist_genre)) +\n  geom_bar(aes(y=..count..), stat = \"count\", position = \"dodge\") +\n  labs(x = \"Number of Songs per Album\", y = \"Number of Instances of Albums\", \n       title = \"Albums by Number of Songs Included\") +\n  scale_x_continuous(limits = c(1.5, 8), breaks = 0:8) +\n  scale_fill_manual(values = c(\"red\",\"green\",\"blue\",\"orange\",\"purple\",\"cyan\"))\n\n\n\n\n\n\n\n\n\n\n\nLooking at trends of song titles’ lengths and genericnesses over time\nNow, let’s look at the length of song titles per genre. Here, we look at both a) the number of words in a song’s title by genre, b) the number of characters in a song’s title by genre. Although values are again close, we can see here that rap has both the lowest amount of words and length in terms of characters, and EDM has the highest. Using previous hypotheses, we can hypothesize that since EDM has less songs per album, the titles are more descriptive, the opposite for rap. Another hypothesis is since rap has a lot of words used in the song, the title should be less discriminating to the content, therefore more general, resulting in a shorter title. Again, these are all hypotethical ideas.\n\n\nShow source code\ntitle_lengths &lt;- spotify_songs |&gt;\n  filter(!is.na(track_name)) |&gt;\n  mutate(word_count = str_count(track_name, \"\\\\w+\"), title_charlength = str_length(str_extract_all(track_name,\"\\\\w+\"))) |&gt; \n  group_by(playlist_genre) |&gt;\n  summarise(avg_word_count = mean(word_count), avg_title_length = mean(unlist(title_charlength)), total_songs = n())\nprint(title_lengths)\n\n\n# A tibble: 6 × 4\n  playlist_genre avg_word_count avg_title_length total_songs\n  &lt;chr&gt;                   &lt;dbl&gt;            &lt;dbl&gt;       &lt;int&gt;\n1 edm                      3.48             29.6        6043\n2 latin                    3.04             25.5        5153\n3 pop                      3.20             26.5        5507\n4 r&b                      3.31             27.0        5431\n5 rap                      2.94             24.3        5743\n6 rock                     3.45             29.4        4951\n\n\nLooking at the number of words in songs over their release year, we can obtain the following graph for songs between 1970 and 2015. If we model with a linear regression line, we can see a stark decrease in word usage over the decades in song titles. A few reasons why this might be are the need for more unique titles as generic titles for songs have already been taken therefore the usage of more unique and concentrated words; the ease of marketing shorter titled songs; the ease of access to songs via web-streaming and industrialization in production processes resulting in the need of less “refined” titles. Either way, according to the data set, the decrease in number of words over the years is evident. From the 4.0 levels in the 1970s, we reach the 3.4 words per title levels in the 2010s. I have omitted pre-1970 and 2015-2020 data due to less data points during those years.\n\n\nShow source code\nsongstemp &lt;- spotify_songs |&gt;\n  filter(!is.na(track_name) & track_name!=\"\") |&gt;\n  mutate(year = as.numeric(substr(track_album_release_date, 1,4)), word_count = str_count(track_name, \"\\\\w+\")) |&gt;\n  filter(!is.na(year) & year&gt;=1970 & year&lt;=2015) |&gt;\n  group_by(year) |&gt;\n  summarise(avg_word_count = mean(word_count), total_songs = n())\n\nggplot(songstemp, aes(x = year, y = avg_word_count)) +\n  geom_point(color = \"red\", size = 3) + \n  geom_line(color = \"red\", size = 1) + \n  geom_smooth(method = \"lm\", color = \"darkblue\") + \n  labs(x = \"Song Release Year\", y = \"Average Word Count in Song Title\",\n       title = \"Average Number Words in Songs vs. their Release Year (1970-2015)\")\n\n\n\n\n\n\n\n\n\nFinally, let’s take a look at a generic type of song titles: the word “the” followed by a singular random word (i.e. the song title is two words: “The __“). A famous song that immediately popped into my mind fitting this rule is”The Unforgiven” by Metallica. Let’s now search for the number of songs that fit this rule. We know from a previous data table that the average number of songs per genre is about 5000-6000. This leaves songs with the exact format of “The” and another word at around 1% over most genres. One genre standing out is Latin, which may be caused by Latin songs frequently having non-English therefore non-“The” titles.\n\n\nShow source code\nthe_songs &lt;- spotify_songs |&gt;\n  filter(!is.na(track_name)) |&gt;\n  mutate(the_anyword = str_detect(tolower(track_name), \"^the\\\\s{1}\\\\w+$\")) |&gt;\n  filter(the_anyword) |&gt;\n  group_by(playlist_genre) |&gt;\n  summarise(the_songs_numberof = n())\nprint(the_songs)\n\n\n# A tibble: 6 × 2\n  playlist_genre the_songs_numberof\n  &lt;chr&gt;                       &lt;int&gt;\n1 edm                            59\n2 latin                          14\n3 pop                            55\n4 r&b                            39\n5 rap                            51\n6 rock                           64\n\n\n\n\nSource Used\nAccess at: https://github.com/rfordatascience/tidytuesday/blob/main/data/2020/2020-01-21/readme.md. The source states that the data comes from Spotify’s API via the spotifyr package. Authors of the package are Charlie Thompson, Josiah Parry, Donal Phipps, and Tom Wolff. Kaylin Pavlik had a recent blogpost using the audio features to explore and classify songs. She used the spotifyr package to collect about 5000 songs from 6 main categories (EDM, Latin, Pop, R&B, Rap, & Rock) in creation of this data set. h/t to Jon Harmon & Neal Grantham."
  },
  {
    "objectID": "SongAnalysis.html",
    "href": "SongAnalysis.html",
    "title": "Songs Text Analysis",
    "section": "",
    "text": "We will be analyzing a data set of Spotify songs up to 2020. The data set source can be found at the very bottom of the page. We will be looking at trends in how many songs there is expected to be in a given album depending on genre, and will be analyzing how song titles changed over the decades. To start, we import our data.\n\n\nShow source code\ntuesdata &lt;- tidytuesdayR::tt_load('2020-01-21')\ntuesdata &lt;- tidytuesdayR::tt_load(2020, week = 4)\nspotify_songs &lt;- tuesdata$spotify_songs\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(dplyr)\n\n\n\nLooking at trends of the expected number of songs per album\nFirst, let’s take a look at the average number of songs per album. A lot of artists put up “singles”; so, in order to remove them, we filter for number of songs over 1 per album. Oftentimes, the most mainstream albums come with 7 to 12 or 13 songs per album. However, the data shows that less number of songs is more common for albums. The most common instance is 2 songs per album, then 3, etc.. This could be caused by smaller artists also being featured on Spotify and them having usually no restriction on a minimum amount of songs per album, or having any concern to release a bunch of songs at one time (they can do this over time). We see that all genres are not too extremely off from each other in songs per album; however, we see noticeable differences. Where EDM has about 2.42 songs per album, rap has 3.15. This may possibly be caused by the more vibrant and less-lyrics based nature of EDM opposed to the lyrics-heavy nature of rap. Lack of lyrics may possibly constitute in having less songs in a given album as it is harder to produce unique music with the element of just electronic music and the absence of words. EDM also tends to have the highest number of covers out of any genre as it is easier to mix-match, partly due to its relative lack of lyrics and technological produce again; where covers are only popular with popular songs, automatically making less-popular songs less covered, meaning less songs per a given album.\n\n\nShow source code\navg_songs_per_album &lt;- spotify_songs |&gt;\n  group_by(playlist_genre, track_album_id) |&gt;\n  summarise(songs_per_album = n()) |&gt;\n  group_by(playlist_genre) |&gt;\n  filter(songs_per_album &gt; 1) |&gt;\n  summarise(avg_songs_per_album = mean(songs_per_album))\nprint(avg_songs_per_album)\n\n\n# A tibble: 6 × 2\n  playlist_genre avg_songs_per_album\n  &lt;chr&gt;                        &lt;dbl&gt;\n1 edm                           2.42\n2 latin                         2.82\n3 pop                           2.76\n4 r&b                           3.09\n5 rap                           3.16\n6 rock                          2.95\n\n\nNow, let’s plot the number of songs per album and their instances detailing genres. What this graph tells us different to the data table above is the quickness in decrease of number of instances as number of songs per album increases. Expectedly, EDM, with the red bars, decreases quite fast compared to other genders as we go more right on the x-axis. Rap has quite a slower decreasing curve. Perhaps another color one might catch is orange, which constitutes to R&B, having quite a close curve to that of rap. If we look at our data table above, we see that R&B has a value that is quite close to rap, which fulfills our expectations.\n\n\nShow source code\nsongs_per_album_per_genre &lt;- spotify_songs |&gt;\n  group_by(playlist_genre, track_album_id) |&gt;\n  summarise(songs_per_album = n()) |&gt;\n  filter(songs_per_album &gt; 1)\n\nggplot(songs_per_album_per_genre, aes(x = songs_per_album, fill = playlist_genre)) +\n  geom_bar(aes(y=..count..), stat = \"count\", position = \"dodge\") +\n  labs(x = \"Number of Songs per Album\", y = \"Number of Instances of Albums\", \n       title = \"Albums by Number of Songs Included\") +\n  scale_x_continuous(limits = c(1.5, 8), breaks = 0:8) +\n  scale_fill_manual(values = c(\"red\",\"green\",\"blue\",\"orange\",\"purple\",\"cyan\"))\n\n\n\n\n\n\n\n\n\n\n\nLooking at trends of song titles’ lengths and genericnesses over time\nNow, let’s look at the length of song titles per genre. Here, we look at both a) the number of words in a song’s title by genre, b) the number of characters in a song’s title by genre. Although values are again close, we can see here that rap has both the lowest amount of words and length in terms of characters, and EDM has the highest. Using previous hypotheses, we can hypothesize that since EDM has less songs per album, the titles are more descriptive, the opposite for rap. Another hypothesis is since rap has a lot of words used in the song, the title should be less discriminating to the content, therefore more general, resulting in a shorter title. Again, these are all hypotethical ideas.\n\n\nShow source code\ntitle_lengths &lt;- spotify_songs |&gt;\n  filter(!is.na(track_name)) |&gt;\n  mutate(word_count = str_count(track_name, \"\\\\w+\"), title_charlength = str_length(str_extract_all(track_name,\"\\\\w+\"))) |&gt; \n  group_by(playlist_genre) |&gt;\n  summarise(avg_word_count = mean(word_count), avg_title_length = mean(unlist(title_charlength)), total_songs = n())\nprint(title_lengths)\n\n\n# A tibble: 6 × 4\n  playlist_genre avg_word_count avg_title_length total_songs\n  &lt;chr&gt;                   &lt;dbl&gt;            &lt;dbl&gt;       &lt;int&gt;\n1 edm                      3.48             29.6        6043\n2 latin                    3.04             25.5        5153\n3 pop                      3.20             26.5        5507\n4 r&b                      3.31             27.0        5431\n5 rap                      2.94             24.3        5743\n6 rock                     3.45             29.4        4951\n\n\nLooking at the number of words in songs over their release year, we can obtain the following graph for songs between 1970 and 2015. If we model with a linear regression line, we can see a stark decrease in word usage over the decades in song titles. A few reasons why this might be are the need for more unique titles as generic titles for songs have already been taken therefore the usage of more unique and concentrated words; the ease of marketing shorter titled songs; the ease of access to songs via web-streaming and industrialization in production processes resulting in the need of less “refined” titles. Either way, according to the data set, the decrease in number of words over the years is evident. From the 4.0 levels in the 1970s, we reach the 3.4 words per title levels in the 2010s. I have omitted pre-1970 and 2015-2020 data due to less data points during those years.\n\n\nShow source code\nsongstemp &lt;- spotify_songs |&gt;\n  filter(!is.na(track_name) & track_name!=\"\") |&gt;\n  mutate(year = as.numeric(substr(track_album_release_date, 1,4)), word_count = str_count(track_name, \"\\\\w+\")) |&gt;\n  filter(!is.na(year) & year&gt;=1970 & year&lt;=2015) |&gt;\n  group_by(year) |&gt;\n  summarise(avg_word_count = mean(word_count), total_songs = n())\n\nggplot(songstemp, aes(x = year, y = avg_word_count)) +\n  geom_point(color = \"red\", size = 3) + \n  geom_line(color = \"red\", size = 1) + \n  geom_smooth(method = \"lm\", color = \"darkblue\") + \n  labs(x = \"Song Release Year\", y = \"Average Word Count in Song Title\",\n       title = \"Average Number Words in Songs vs. their Release Year (1970-2015)\")\n\n\n\n\n\n\n\n\n\nFinally, let’s take a look at a generic type of song titles: the word “the” followed by a singular random word (i.e. the song title is two words: “The __“). A famous song that immediately popped into my mind fitting this rule is”The Unforgiven” by Metallica. Let’s now search for the number of songs that fit this rule. We know from a previous data table that the average number of songs per genre is about 5000-6000. This leaves songs with the exact format of “The” and another word at around 1% over most genres. One genre standing out is Latin, which may be caused by Latin songs frequently having non-English therefore non-“The” titles.\n\n\nShow source code\nthe_songs &lt;- spotify_songs |&gt;\n  filter(!is.na(track_name)) |&gt;\n  mutate(the_anyword = str_detect(tolower(track_name), \"^the\\\\s{1}\\\\w+$\")) |&gt;\n  filter(the_anyword) |&gt;\n  group_by(playlist_genre) |&gt;\n  summarise(the_songs_numberof = n())\nprint(the_songs)\n\n\n# A tibble: 6 × 2\n  playlist_genre the_songs_numberof\n  &lt;chr&gt;                       &lt;int&gt;\n1 edm                            59\n2 latin                          14\n3 pop                            55\n4 r&b                            39\n5 rap                            51\n6 rock                           64\n\n\n\n\nSource Used\nAccess at: https://github.com/rfordatascience/tidytuesday/blob/main/data/2020/2020-01-21/readme.md. The source states that the data comes from Spotify’s API via the spotifyr package. Authors of the package are Charlie Thompson, Josiah Parry, Donal Phipps, and Tom Wolff. Kaylin Pavlik had a recent blogpost using the audio features to explore and classify songs. She used the spotifyr package to collect about 5000 songs from 6 main categories (EDM, Latin, Pop, R&B, Rap, & Rock) in creation of this data set. h/t to Jon Harmon & Neal Grantham."
  },
  {
    "objectID": "HomeAdvantageOlympics.html",
    "href": "HomeAdvantageOlympics.html",
    "title": "Home Advantage in the Olympics",
    "section": "",
    "text": "Introduction\nThis analysis tests whether in the Summer Olympics, on a per athlete basis, a home advantage exists or not. This analysis builds on a TidyTuesday dataset, analyzing the 8 Summer Olympic hosts and their competing teams 7 times abroad and 1 time as host between 1988-2016. By contrasting the variable, average number of medal points per athlete for a given nation, with whether that nation was a host of the Summer Olympics at that instance of competition or not, we draw statistical conclusions regarding if a “Home Advantage” exists for olympic hosts. “Home Advantages” can greatly influence athletic performance and results in competitions. It is important to remember throughout this analysis that our “Home Advantage” is calculated on a per participating athlete basis. In this analysis, we in fact show that a statistical significance of “Home Disadvantage” exists on a per participating athlete basis.\n\n\nHypothesis and Dataset\nHypotheses:\nNull Hypothesis: Whether a country hosts the Summer Olympics or not does not have an effect on per capita medal wins for that country.\nAlternative Hypothesis: Whether a country hosts the Summer Olympics or not does have an effect on per capita medal wins for that country (either positively, resulting in an advantage, or negatively, resulting in a disadvantage).\nOur alternative hypothesis is that the null hypothesis is incorrect; however, in order to draw a possible more precise statistical conclusion, in the event our alternative hypothesis is shown to be true, we will also be calculating 2 different p-values in order to conclude if hosting the summer olympics yields better results on a per participating athlete basis or not (not just that it has a statistical significance).\n\ntuesdata &lt;- tidytuesdayR::tt_load('2024-08-06')\nolympics &lt;- tuesdata$olympics\nlibrary(purrr)\nlibrary(tidyverse)\nlibrary(tidytuesdayR)\nlibrary(ggplot2)\n\nHere is a small snapshot of the data set we are working with:\n\nolympics\n\n# A tibble: 271,116 × 15\n      id name     sex     age height weight team  noc   games  year season city \n   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;\n 1     1 A Dijia… M        24    180     80 China CHN   1992…  1992 Summer Barc…\n 2     2 A Lamusi M        23    170     60 China CHN   2012…  2012 Summer Lond…\n 3     3 Gunnar … M        24     NA     NA Denm… DEN   1920…  1920 Summer Antw…\n 4     4 Edgar L… M        34     NA     NA Denm… DEN   1900…  1900 Summer Paris\n 5     5 Christi… F        21    185     82 Neth… NED   1988…  1988 Winter Calg…\n 6     5 Christi… F        21    185     82 Neth… NED   1988…  1988 Winter Calg…\n 7     5 Christi… F        25    185     82 Neth… NED   1992…  1992 Winter Albe…\n 8     5 Christi… F        25    185     82 Neth… NED   1992…  1992 Winter Albe…\n 9     5 Christi… F        27    185     82 Neth… NED   1994…  1994 Winter Lill…\n10     5 Christi… F        27    185     82 Neth… NED   1994…  1994 Winter Lill…\n# ℹ 271,106 more rows\n# ℹ 3 more variables: sport &lt;chr&gt;, event &lt;chr&gt;, medal &lt;chr&gt;\n\n\n\n\nData Mutation\nLet us first mutate our data set so as to help us in investigating per capita medal wins per participating country, for the Summer Olympics. In this light, we will mutate the data set so that we have a column that has medal wins per participating athlete, so that countries sending more athletes are not advantaged on a per athlete basis. Regarding the weighting of medals, we will count bronze medals as 1 medal point, silver medals as 2, and gold as 3 in order to better highlight a possible advantage, if there is one, that a country might have. No medal (NA) means 0 medal points, and joint medals will be awarded as their respective full medal’s medal points to both athletes/teams. Furthermore, we will mutate our data set so that we only analyze Summer Olympics. We will also analyze Olympics from only 1988 in order to have one instance of hosting per country, as both the 1984 and 1996 Olympics were hosted by the US. We are also doing this as to not go into issues with countries having different names/changing territories. Our data set runs until 2016.\n\n# Selecting only Summer Olympics\nolympicsdata &lt;- olympics |&gt;\n  filter(season==\"Summer\")\n\n# Assigning medal point values\nolympicsdata &lt;- olympicsdata |&gt;\n  mutate(medal_points = case_when(medal==\"Gold\" ~ 3, medal==\"Silver\" ~ 2, medal==\"Bronze\" ~ 1, medal==\"NA\" ~ 0, TRUE ~ 0))\n\n#Selecting years from only 1988 to 2016\nolympicsdata &lt;- olympicsdata |&gt;\n  filter(year &gt;= 1988 & year &lt;= 2016)\n\n# Defining a function to change city names into their respective countries (as if they were in 2025) so that we can compare teams and countries for home-field advantage\nhostcitytocountry &lt;- function(olympicsdata, city) {\n  hostcitytocountry &lt;- data.frame(\n    city = c(\"Seoul\", \"Barcelona\", \"Atlanta\", \"Sydney\", \"Athina\", \"Beijing\", \"London\", \"Rio de Janeiro\"),\n    country = c(\"South Korea\", \"Spain\", \"United States\", \"Australia\", \"Greece\", \"China\", \"Great Britain\", \"Brazil\"))\n  updatedolympicsdata &lt;- olympicsdata |&gt;\n    left_join(hostcitytocountry, by = setNames(\"city\", city)) |&gt;\n    mutate(!!city := country) |&gt; select(-country) \n}\n\nolympicsdata &lt;- hostcitytocountry(olympicsdata, \"city\")\nolympicsdata\n\n# A tibble: 106,268 × 16\n      id name     sex     age height weight team  noc   games  year season city \n   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;\n 1     1 A Dijia… M        24    180   80   China CHN   1992…  1992 Summer Spain\n 2     2 A Lamusi M        23    170   60   China CHN   2012…  2012 Summer Grea…\n 3    12 Jyri Ta… M        31    172   70   Finl… FIN   2000…  2000 Summer Aust…\n 4    13 Minna M… F        30    159   55.5 Finl… FIN   1996…  1996 Summer Unit…\n 5    13 Minna M… F        34    159   55.5 Finl… FIN   2000…  2000 Summer Aust…\n 6    18 Timo An… M        31    189  130   Finl… FIN   2000…  2000 Summer Aust…\n 7    21 Ragnhil… F        27    163   NA   Norw… NOR   2008…  2008 Summer China\n 8    22 Andreea… F        22    170  125   Roma… ROU   2016…  2016 Summer Braz…\n 9    23 Fritz A… M        22    187   89   Norw… NOR   2000…  2000 Summer Aust…\n10    23 Fritz A… M        26    187   89   Norw… NOR   2004…  2004 Summer Gree…\n# ℹ 106,258 more rows\n# ℹ 4 more variables: sport &lt;chr&gt;, event &lt;chr&gt;, medal &lt;chr&gt;, medal_points &lt;dbl&gt;\n\n\nWe now have a data table easier to work with in light of our aim. We will now extract data from this data table to create a separate data table, where we will have the competing team, the average medal points per athlete from that country in a given year of the summer olympics, the country that the host city is in, and the year of the summer olympics. We do this for all 8 hosts between 1988-2016 and their sports teams.\n\n# Defining host countries for easier data use\nhost_countries &lt;- c(\"South Korea\", \"Spain\", \"United States\", \"Australia\", \"Greece\", \"China\", \"Great Britain\", \"Brazil\")\n\n# Summarizing data table based on competing team, calculating the average medal points per athlete per country by summing up number of athletes and averaging out, host city country, and year; and summarizing in a data table organized alphabetically by team country name.\nfinal_table &lt;- map_dfr(host_countries, function(country) {\n  olympicsdata |&gt;\n    filter(team==country) |&gt;\n    group_by(team, year, city) |&gt;\n    summarise(average_medal_points = mean(medal_points, na.rm = TRUE),  \n      athletes_per_team = n_distinct(id), .groups = \"drop\") |&gt;\n    mutate(average_medal_points_per_athlete = (average_medal_points/athletes_per_team)) |&gt;\n    select(team, average_medal_points_per_athlete, city, year) \n}) |&gt; arrange(team)\n\nfinal_table\n\n# A tibble: 64 × 4\n   team      average_medal_points_per_athlete city           year\n   &lt;chr&gt;                                &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1 Australia                         0.000901 South Korea    1988\n 2 Australia                         0.00103  Spain          1992\n 3 Australia                         0.000940 United States  1996\n 4 Australia                         0.000797 Australia      2000\n 5 Australia                         0.00123  Greece         2004\n 6 Australia                         0.00105  China          2008\n 7 Australia                         0.000929 Great Britain  2012\n 8 Australia                         0.000767 Brazil         2016\n 9 Brazil                            0.00113  South Korea    1988\n10 Brazil                            0.000967 Spain          1992\n# ℹ 54 more rows\n\n\n\n\nResults\nLet us now graph these teams’ performances per athlete over the years.\n\n# Extracting host/not host information, to be used in graphing and calculations\nfinal_table &lt;- final_table |&gt;\n  mutate(host_or_not = ifelse(city==team, \"Yes\", \"No\"))\n\n# Calculating the average medal points per athlete when country is the host\nhosts_average &lt;- final_table |&gt;\n  filter(host_or_not==\"Yes\") |&gt;\n  summarise(host_average_medal_points = mean(average_medal_points_per_athlete, na.rm = TRUE)) |&gt;\n  pull(host_average_medal_points)\n\n# Calculating the average medal points per athlete, regardless of if country is host or not\noverall_average &lt;- final_table |&gt;\n  summarise(overall_average_medal_points = mean(average_medal_points_per_athlete, na.rm = TRUE)) |&gt;\n  pull(overall_average_medal_points)\n\n# Plotting each country's scatterplot, non-host data points small black, host data points triangle, and average medal points per athlete lines for both overall and host-only\nggplot(final_table, aes(x = factor(year), y = average_medal_points_per_athlete, group = team, color = team)) +\n  geom_line(size = 1.2, alpha = 0.65) +\n    geom_point(aes(shape = host_or_not), size = ifelse(final_table$host_or_not==\"Yes\", 5.2, 2), color = \"black\") + \n  scale_shape_manual(values = c(\"Yes\" = 17, \"No\" = 16)) +\n  scale_fill_manual(values = c( \"red\", \"red\")) +\n  scale_x_discrete(labels=function(a) gsub(\"\\\\.\", \" \", a)) + \n  labs(x = \"Year\", \n    y = \"Average Medal Points per Athlete\", \n    title = \"Average Medal Points per Athlete for Host Countries (1988-2016)\") +\n  theme_minimal() + theme(legend.position = \"bottom\") +\n  geom_hline(yintercept = hosts_average, linetype = \"dashed\", color = \"red\", size = 1) + geom_hline(yintercept = overall_average, linetype = \"dashed\", color = \"black\", size = 1)\n\n\n\n\n\n\n\n\nThe above graph shows each team’s athletes’ average medal points for each year of the competition. Each data point is marked with a black dot, where each country’s statistics are shown with a semi-opaque colored line. If the country was host that year in which it was competing, its data points are shown with a big triangle.\nShown with the dashed black line on the graph, if we average out all data points (whether the country was host or not), we get an average medal point per athlete of:\n\noverall_average\n\n[1] 0.001065398\n\n\nShown with the dashed red line on the graph, if we average out all data points (whether the country was host or not), we get an average medal point per athlete of:\n\nhosts_average\n\n[1] 0.0007362636\n\n\nThis means that athletes who are qualified to the Olympics are 44.7% more likely, on average, to score a medal if their country is not the host for that year, according to our data set.\n\n\nPermutation Test\nIn order to do a permutation test, let’s add a simple column showing whether if the country was the host or not for a given average medal points per athlete for a given Summer Olympics, appending it to our data table above.\n\nfinal_table &lt;- final_table |&gt; \n  mutate(host_or_not = ifelse(team==city, \"Yes\", \"No\"))\n\nfinal_table\n\n# A tibble: 64 × 5\n   team      average_medal_points_per_athlete city           year host_or_not\n   &lt;chr&gt;                                &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;      \n 1 Australia                         0.000901 South Korea    1988 No         \n 2 Australia                         0.00103  Spain          1992 No         \n 3 Australia                         0.000940 United States  1996 No         \n 4 Australia                         0.000797 Australia      2000 Yes        \n 5 Australia                         0.00123  Greece         2004 No         \n 6 Australia                         0.00105  China          2008 No         \n 7 Australia                         0.000929 Great Britain  2012 No         \n 8 Australia                         0.000767 Brazil         2016 No         \n 9 Brazil                            0.00113  South Korea    1988 No         \n10 Brazil                            0.000967 Spain          1992 No         \n# ℹ 54 more rows\n\n\nIn order to do a permutation test, we now take the variables host_or_not, telling us if a city is a host or not, and average_medal_points_per_athlete, telling the average medal points for athletes at a given year from a given team at the Summer Olympics, from the above table. While doing a permutation test, we discard whether if the average_medal_points_per_athlete is by a host nation instance or not, and we randomize/shuffle (here 10000 times) to create a normal distribution of a case where average_medal_points_per_athlete randomly varied, but assuming host_or_not was not a factor. This is called our Null Distribution.\n\n# Code heavily helped by DS002 Lecture Notes, cited down below\n\n# Creating the permutation test data\nperm_data &lt;- function(rep, data){\n  data |&gt; \n    select(host_or_not, average_medal_points_per_athlete) |&gt; \n    mutate(math_perm = sample(average_medal_points_per_athlete, replace = FALSE)) |&gt; \n    group_by(host_or_not) |&gt; \n    summarize(points_avg = mean(average_medal_points_per_athlete),\n              perm_avg = mean(math_perm)) |&gt; \n    summarize(points_avg_diff = diff(points_avg),\n              perm_avg_diff = diff(perm_avg),\n              rep = rep)\n}\n\n# Setting seed and shuffling 10000 times\nset.seed(4747)\nperm_stats &lt;- map(c(1:10000), perm_data, data = final_table) |&gt; \n  list_rbind() \n\n# Plotting it on a histogram with red lines showing our dataset's case testing for extremes.\nperm_stats |&gt; \n  ggplot(aes(x = perm_avg_diff)) + \n  geom_histogram() + \n  geom_vline(aes(xintercept = points_avg_diff), color = \"red\")\n\n\n\n\n\n\n\n# Calculating p-values for both an advantage condition or a disadvantage condition\nperm_stats |&gt; \n  summarize(\"Advantage\", p_value_avg = mean(perm_avg_diff &gt; points_avg_diff))  \n\n# A tibble: 1 × 2\n  `\"Advantage\"` p_value_avg\n  &lt;chr&gt;               &lt;dbl&gt;\n1 Advantage           0.989\n\nperm_stats |&gt; \n  summarize(\"Disadvantage\", p_value_avg = mean(perm_avg_diff &lt; points_avg_diff))\n\n# A tibble: 1 × 2\n  `\"Disadvantage\"` p_value_avg\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 Disadvantage          0.0107\n\n\nPlease note since our hypothesis tests for both an advantage condition or disadvantage condition, we have two p-values for either relationship. In our case, looking at the values, we can conclude that there is a disadvantage relationship in our hypothesis, which we will get to now.\n\n\nConclusion\nFrom our data, we see that athletes who are qualified to the Olympics are 44.7% more likely, on average, to score a medal if their country is not the host for that year. Furthermore, according to our p-value calculation, our alternative hypothesis is shown in the disadvantaged direction, as we have reached a p-value of 0.0107, as this is less than the p-value of 0.05 generally accepted by the modern-day scientific institution (2025). This p-value looks at the probability that our data set might have randomly been on the left of the red line in the above graph. The advantaged direction would have looked at the right of the red line, which would obviously been an unacceptable conclusion.\nTo reiterate, we show that athletes who are qualified to the Olympics are 44.7% more likely, on average, to score a medal if their country is not the host for that year. This might seem counter-intuitive at first, as most research shows that in athletics a “Home Advantage” is quite significant. Factors such as fan support, fan or bureaucratic pressure on judges/referees, similar climate/sports hall conditions, similar cuisine, possible non-temporary stays during the competition all favor the home team. So, what might be the cause that we actually seem to have a “Home Disadvantage”?\nWe had established that our analysis was on a per athlete basis. It is most likely true, that all these factors are noticeably helping the home team. However, the home team also is generally allowed to bring a very significant amount of more athletes from its own nation than it can send abroad for another olympic competition, per se. This is possibly a combination of wildcard entrees being awarded to the host more often, pre-determined extra quotas for the host, and a big relief in budgeting for sponsoring athletes domestically and not internationally.\nOf course, assuming the supply of world-class athletes are limited, the home country will fill the rest of the spots with less-likely-world-class athletes. This likely will result in overall worse performance by those athletes. Furthermore, the number of medals stays the same regardless of how many athletes from a country compete. For all these reasons, due to the average quality of athletes going down as a result of lower qualifying standards due to a supply of more available positions, on a per athlete basis, hosts of Summer Olympics events are disadvantaged according to our data set. Our closest estimate, according to the cross-competitions of the 8 Summer Olympics hosts from 1988 to 2016 over this time interval, that athletes from these countries during this interval were 44.7% more likely, on average, to score a medal if their country was not the host for that year.\nWe have shown a statistical significance showing our alternate hypothesis that hosting a Summer Olympics does have a negative effect on the number medals earned per participating athlete capita. This is backed by a p-value of 0.0107.\n\n\nSources\nTidyTuesdayR package obtained from https://github.com/rfordatascience/tidytuesday/blob/main/data/2024/2024-08-06/readme.md. Provided by ‘jonthegeek’, published on 2024-08-06 borrowing from previously published data also via TidyTuesday (2021-07-27).\nCoding help obtained from: https://ds002r-fds.netlify.app/slides/2025-03-26-perm. With many thanks to Prof. Hardin."
  },
  {
    "objectID": "DataScienceEthics.html",
    "href": "DataScienceEthics.html",
    "title": "Facial Recognition and Data Ethics Problems",
    "section": "",
    "text": "Background\nArtificial Intelligence is used in every part of our daily lives now – in circumstances in which we realize it and in those we do not. One way of rating or classifying people, often used ethically but also just as often used unethically, is via using their face, gender, and/or skin color data. Facial recognition software are used everywhere: from direct applications such as perhaps opening your phone with a Face ID or going through automatic passport check-in to modifiable applications such as your facial data being used in order to help admit you to a job or for governmental purposes. Even if the uses can be in good light and most facial classification software might try to use it in order to promote just and fair decisions, regardless, the data itself may still be unsuitable for such purposes without initial cleansing and bias considerations.\nAccording to Buolamwini and Gebru’s study “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification”, skin and facial data is highly skewed towards those with lighter skin and significantly skewed towards those who are classified as male. Many data-users who do not realize this, or do not adjust their outcomes to this bias, even if they make their AI take decisions in good light, end up having decisions which strongly favor lighter skinned individuals or male ones. This can be either because of the abundance of those types of facial data being more abundant will make the algorithm more confident to choose them, or more importantly, since algorithms will be trained on past data, past usages per capita being more abundant for lighter skinned individuals or male individuals will make the algorithm think that it is more positive by nature to choose such individuals; amongst other reasons. This bias has huge significance in our modern day world where increasingly AI is making decisions instead of humans. Buolamwini and Gebru’s study also highlights how misclassification of racial data for computer vision can be a reason for inaccuracies in fairness, for example for mixed-race or in-between skin colors individuals, highlighting that people groups’ phenotypes can change over time and represents a broad spectrum.\nAnother study by Denise Almeida, Konstantin Shmarko, and Elizabeth Lomas compares the different actions for facial recognition software that is being taken in the UK, EU, and the US. They highlight that with COVID-19, facial recognition has multiplied in terms of importance. They state that for the EU and UK, although a facial recognition oriented privacy act does not exist, the EU’s general data protection law, the General Data Protection Regulation (GDPR) protects local or foreign companies from using EU citizens’ data in certain ways. A lot of these uses would normally be covered in a long terms of use elsewhere in the world and freely used. However, the authors still claim that these measures are not enough. On the other hand, according to the paper, a framework in the USA does not exist for facial recognition software data privacy; however, some California cities have banned the usage of any facial recognition technology and some companies like IBM and Amazon have promised and taken action to double down on not using facial recognition software for usages that may be harmed by inclusions of biases. However, when looked at the issue as a widespread problem, more actions should be taken all around the world in terms of data privacy as well. This raises questions in using such data in which where they come from or what kinds of biases they may include is or may be vague.\nAs it stands, the commercial usage of facial recognition software is a very important and relevant issue, as so many possibilities of unethical usage exist: most facial recognition data itself is skewed towards biasing males or lighter skinned people, and the sharing of this data and if there were biases inputted into the data by itself is vague. Even if someone wanted to use the data with good intentions, it is highly improbable that the data that they have is fully ethically sound.\nSome questions or points that may come up as good discussion prompts for facial recognition AI and ethics and for Buolamwini and Gebru’s study “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification” are as follows:\n\n\nWho was measured? Are those individuals representative of the people to whom we’d like to generalize / apply the algorithm? Should we analyze data if we do not know how the data were collected?\nBuolamwini and Gebru exactly highlight in their study that the individuals that are part of the data sets for most usages of facial recognition data are not representative of the people whom we’d like to generalize. The people whom we’d like to generalize would be the general public, with as low bias or none, if at all possible, towards any group that an individual could belong to. An ideal algorithm would look at the individual and not be biased by groups (ethnic, religious, sexual, etc.) that the individual may be part of. Instead, people who were measured were mostly lighter skinned or males. Furthermore, Denise Almeida, Konstantin Shmarko, and Elizabeth Lomas’s also touch upon how there is a lack of transparency in big facial recognition data and where it comes from, or how it is processed. If we don’t know how the data was collected, for scientific purposes, it cannot be ethical to use it. For commercial purposes, using and implementing this data would mean some people would be unfairly disadvantaged, which in that case, it is not fully ethical to use it either. The data we have for facial recognition as it currently stands is not unbiased, and Buolamwini and Gebru do a good job at pointing this out.\n\n\nShould race be used as a variable? Is it a proxy for something else? What about gender?\nThe question of if race should be used as a variable is a question about affirmative action or no affirmative action. Without a doubt, affirmative action has had its benefits and also negatives. It is such an important topic and both sides of the argument are heavy. If the data will be used to judge one on solely meritocratic grounds, it may be best to not use race as a variable. However, this also depends on what you call “fair”, as people from disadvantaged groups would have a harder time getting to those meritocratic grounds anyways, as the real world is far from meritocratic. This decision would have to depend on the individual study, but, transparency is key in any usage of data. Regarding if race is a proxy for something else, Buolamwini and Gebru specifically talk about this. They say that labeling skin tones in certain ways diminishes the attention to detail we can give to perhaps skin colors that lie in-between labels as they would have to be put at one category or the other. Same with gender, they say:\n\n“All evaluated companies provided a “gender classification” feature that uses the binary sex labels of female and male. This reductionist view of gender does not adequately capture the complexities of gender or address transgender identities. The companies provide no documentation to clarify if their gender classification systems which provide sex labels are classifying gender identity or biological sex.”\n\nTherefore, it is not completely ethical to label pigmentation as certain classes of skin color. However, it is not feasible nor comparatively useful with current technology to not label either. Again, companies or data-users should do their best to be transparent about whatever they do. Buolamwini and Gebru say that the companies that they analyzed do not provide any documentation to clarify how gender was defined. This would be an unethical use of the data. Again, if companies are to do classifications, which is a question of ethics on their own, they must provide transparency on what those classifications are and how they are obtained and used; otherwise, their practices will lack ethical boundaries. Again, Buolamwini and Gebru do a good job at highlighting this.\n\n\nPresenting work in ways that empower others to make better-informed decisions\nAs there would be more lighter skinned individuals and males in data sets, as we know, our algorithms would be biased to pick such individuals. The presentation here is who is picked. If we are aware of the biases, and we feed that into our algorithm, perhaps it would make a better-informed decision in order to mitigate bias as much as possible. In terms of Buolamwini and Gebru’s study, they present their work very diligently, using very relevant data, and citing every other study necessary as they go on. They do this in order to publish a paper that has the exact principle of empowering others (companies, humans, or AI) to make better-informed decisions. The usage of AI for humans is truly an ethical issue. Humanity has never been fully ethical, and AI will get more powerful than humans soon. If people have an ideal of making human-sourced decisions ethically, frameworks about ethics should go hand-in-hand with the AI-processed data that they use as well, not be independent from it.\n\n\nRecognizing and mitigating bias in ourselves and in the data we use\nRecruiters for a role, per se, may also have biases without the usage of AI. Naturally, when interviewing candidates, they see the other person’s skin color. Though they may not realize it, it is possible for them to be subconsciously biased based on their previous life experiences. This is the same with AI: AI’s previous life experiences is the data that it is fed, which we have seen to be disproportionately light skinned and male filled. Buolamwini and Gebru’s study does a great job at pointing this out and helps in order to recognize this bias. People have been for a long time trying not to be biased, and although it has worked in some part, it is not perfect. Perhaps, if we train our AI in such a manner that and/or modify our data set that it is done correctly and ethically, in order to produce ethics-oriented decisions; AI facial recognition may be better at mitigating bias than us one day. However, there is a long way to get there – and this is only possible if everyone realizes that this mitigation of bias is possible if we mitigate bias in every single step: when collecting, using, modifying, training on, and reflecting upon our data and findings altogether.\n\n\nSources\nAlmeida, D., Shmarko, K. & Lomas, E. The ethics of facial recognition technologies, surveillance, and accountability in an age of artificial intelligence: a comparative analysis of US, EU, and UK regulatory frameworks. AI Ethics 2, 377–387 (2022). https://doi.org/10.1007/s43681-021-00077-w.\nBuolamwini, J. & Gebru, T.. (2018). Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. Proceedings of the 1st Conference on Fairness, Accountability and Transparency, in Proceedings of Machine Learning Research 81:77-91 Available from https://proceedings.mlr.press/v81/buolamwini18a.html."
  },
  {
    "objectID": "TrafficStopsAnalysis.html",
    "href": "TrafficStopsAnalysis.html",
    "title": "Tolerance Levels of Traffic Stops in CA Cities",
    "section": "",
    "text": "Introduction\nIn this analysis, our goal is to examine and analyze any trends between citations and warnings for police stops. We will be using data from the Stanford Open Policing Project, which has data from 42 states with many subdivisions, and is cited down below. We will be looking at the trends in California cities, and although they have data on a number of cities, data on whether if citations were issued and whether if warnings were issued both exist for only 4 cities: Oakland, San Francisco, San Diego, and Stockton. Therefore, we will be analyzing any common trends between these cities. We will also aim to draw a conclusion on whether if these cities may have more lenient or more strict treshholds regarding punishments (as shown by the rates of citations and warnings).\n\n\nSQL Data Wrangling\nWe first connect to the SQL server:\n\nlibrary(DBI)\nlibrary(RMariaDB)\ncon_traffic &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"traffic\",\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)\n\nNow, we import the data from the SQL server:\n\nSELECT city,\n  month,\n  SUM(citations_per_month) / SUM(warnings_per_month) AS citations_vs_warnings_ratio,\n  SUM(citations_per_month) AS citations_per_city_per_month,\n  SUM(warnings_per_month) AS warnings_per_city_per_month,\n  SUM(no_punishment_per_month) AS no_punishment_per_city_per_month\n  \nFROM (\nSELECT 'Oakland' AS city,\n    MONTH(date) AS month,\n    IF(citation_issued = 1 AND warning_issued = 0, 1,0) AS citations_per_month,\n    IF(citation_issued = 0 AND warning_issued = 1, 1,0) AS warnings_per_month,\n    IF(citation_issued = 0 AND warning_issued = 0, 1,0) AS no_punishment_per_month\n  FROM ca_oakland_2020_04_01\n  WHERE date IS NOT NULL\n    AND citation_issued IS NOT NULL\n    AND warning_issued IS NOT NULL\n    AND type = 'vehicular'\n    AND YEAR(date) = 2014\n    AND NOT (citation_issued = 1 AND warning_issued = 1)\n\n  UNION ALL\n\n  SELECT 'San Francisco' AS city,\n    MONTH(date) AS month,\n    IF(citation_issued = 1 AND warning_issued = 0, 1,0) AS citations_per_month,\n    IF(citation_issued = 0 AND warning_issued = 1, 1,0) AS warnings_per_month,\n    IF(citation_issued = 0 AND warning_issued = 0, 1,0) AS no_punishment_per_month\n  FROM ca_san_francisco_2020_04_01\n  WHERE date IS NOT NULL\n    AND citation_issued IS NOT NULL\n    AND warning_issued IS NOT NULL\n    AND type = 'vehicular'\n    AND YEAR(date) = 2014\n    AND NOT (citation_issued = 1 AND warning_issued = 1)\n\n  UNION ALL\n\n  SELECT 'San Diego' AS city,\n    MONTH(date) AS month,\n    IF(citation_issued = 1 AND warning_issued = 0, 1,0) AS citations_per_month,\n    IF(citation_issued = 0 AND warning_issued = 1, 1,0) AS warnings_per_month,\n    IF(citation_issued = 0 AND warning_issued = 0, 1,0) AS no_punishment_per_month\n  FROM ca_san_diego_2020_04_01\n  WHERE date IS NOT NULL\n    AND citation_issued IS NOT NULL\n    AND warning_issued IS NOT NULL\n    AND type = 'vehicular'\n    AND YEAR(date) = 2014\n    AND NOT (citation_issued = 1 AND warning_issued = 1)\n\n  UNION ALL\n\n  SELECT 'Stockton' AS city,\n    MONTH(date) AS month,\n    IF(citation_issued = 1 AND warning_issued = 0, 1,0) AS citations_per_month,\n    IF(citation_issued = 0 AND warning_issued = 1, 1,0) AS warnings_per_month,\n    IF(citation_issued = 0 AND warning_issued = 0, 1,0) AS no_punishment_per_month\n  FROM ca_stockton_2020_04_01\n  WHERE date IS NOT NULL\n    AND citation_issued IS NOT NULL\n    AND warning_issued IS NOT NULL\n    AND type = 'vehicular'\n    AND YEAR(date) = 2014\n    AND NOT (citation_issued = 1 AND warning_issued = 1)) AS putting_placeholder\n    \nGROUP BY city, month ORDER BY city, month;\n\nSince Oakland, San Francisco, San Diego, and Stockton all have their own separate data tables, we join them unionwise (Union All, because we have a lot of recurring data points). In our data table, we want the city name, whether if a citation was issued, and whether if a warning was issued. Also, we only want to see the data that was for traffic stops (not pedestrians). Our data existed fully for all cities only between January 2014 and March 2015, so, to keep things consistent, we will only analyze data in 2014. The months those traffic stops happened are numbered 1 through 12. Citations and warnings are usually mutually exclusive; however, it is possible that both may have happened at the same time (perhaps the officer changed their minds, or both a citation and a warning were given for two different reasons in the same stop, etc.). In order to eliminate doubles, we also remove any single stop counting for both a citation and a warning.\nIt is now possible for a traffic stop in our data set to result in no warning or citation, result in a warning, or result in a citation. No warning or citation is the least severe punishment (no punishment at all) and resulting in a citation is the most severe. The ratio-wise prevalence of citations and warnings could be an indicator of how severely traffic stops are handled. However, they also could be an indicator of how accurate the officers are at assessing when to pull over people. In order to dig deep into actual severity of how traffic stops are handled, we can look at the ratio between how many warnings are given and how many citations are given. There being either a citation or a warning will ensure that the driver was actually seen to be in fault; and taking the citation to warning ratio will give us insight on how severe the punishment was for every traffic stop that had the driver at fault.\nTo achieve our aim, we put all the previous queries that are mentioned in the last 2 paragraphs under a subquery, and we write a query to sum up the number of citations, number of warnings, and the number of no punishments per month per city. To extract information from the subquery to the query, we add if statements inside the subquery regarding that specific row’s citation/warning/no punishment status and city and month. In the main query, we finally also calculate the ratio of citations vs. warnings per month per city.\nWe now have all the data we want to work with.\nLet’s now output our table:\n\n#My data table was coming out weird because it didn't fit into the page, so, I looked up how to make it nicer, and this library really does make it nicer. This way, I don't even have to do head( ) because you can just scroll between pages of 10 rows.\n\nlibrary(DT)\n\ndatatable(citations_vs_warnings_per_city_per_month, options = list(scrollX=TRUE))\n\n\n\n\n\nWe see there is some movement between Oakland’s citations vs. warnings ratio over the months, but, we will probably see starker differences between cities instead of between months inside of the same city. We will analyze if such significance exists by data visualization.\nBefore we continue with data visualization, it is good practice to disconnect from the SQL server:\n\nDBI::dbDisconnect(con_traffic)\n\n\n\nData Visualization and Analysis of Citations vs. Warnings Ratio between Cities\nOn to data visualization.\n\nlibrary(ggplot2)\nlibrary(tidyverse)\nggplot(citations_vs_warnings_per_city_per_month, \n       aes(x = month, y = citations_vs_warnings_ratio, color = city, group = city)) +\n  geom_line(size = 1) +\n  geom_point(size = 2.5) +\n  labs(title = \"Citations vs. Warnings Ratio per City in CA per Month in 2014\",\n    x = \"Month in 2014\",\n    y = \"Citations vs. Warnings Ratio\") +\n  scale_x_continuous(breaks = 1:12, labels = month.abb) + ylim(0, NA) + \n  theme_light() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 0.85))\n\n\n\n\n\n\n\n\nThe above graph shows the citations vs. warnings ratio per California city analyzed per month in 2014. The difference between cities is quite noticeable. Stockton hovers around 0.5-1 citations per warning, whereas Oakland and San Francisco are around 2.5-3. Now, we had already established that in order to reduce the crime rate’s influence on deciding how strict punishments in traffic stops are, we were taking the ratio of citations vs. warnings (which means that in theory, all people who get a citation OR warning ARE at fault, but, only those who get a citation are deemed punished severely). Now, although this may reduce the crime rate’s effect, it is not enough of a reason that we do not consider it a reason.\nHowever, could there be other reasons? Perhaps how urban the city is could be a reason. Stockton is considerably less urban than any of the other cities, and San Diego is a much smaller and well-organized city compared to San Francisco or Oakland. San Francisco and Oakland, being a bridge away, are quite comparable in terms of city layout and do not have population prominence (i.e. Oakland is not a “city” because it stands standalone in the middle of the country, but is a city only for governmental purposes, therefore, does not have as high of a “prominence”), For our analysis, it is safe to group SF+Oakland together as the Bay Area.\nSince Stockton, then San Diego, have less population than the Bay Area, these cities having a considerably smaller population (or common-cause being less urban) may be the reason there is a considerable difference, aligning with population/urbanism, for these cities’ citations vs. warnings ratio. This may be caused by a number of factors, but perhaps most prominently; either a smaller population means a more tight-knit community, resulting in officers trusting the goodwill of citizens, or a larger population means officers are not scared to cite law-breakers, as in small cities they may be subject to more personal hatred.\n\n\nData Visualization and Analysis of Citations vs. Warnings Ratio between Months\nWe can see that the citations vs. warnings ratio between cities is quite starkly pronounced, as explained. However, is there also a difference between months inside of cities? We see that Stockton goes up and down in the first half of 2014, and Oakland declines noticeably during the second half of the year; however, it is hard to find a justifiable reason that these may be the case.\nTo be able to possibly find an underlying correlation between months, let’s try to isolate this possible correlation by trying to remove the image of the city-by-city correlation. To do this, let’s now graph the Bay Area cities together vs. San Diego and Stockton together. We will specifically be looking at the development of (the citations to warnings ratio of Bay Area cities averaged) vs. (the citations to warnings ratio of SD & Stockton averaged).\n\nggplot() +\n#ggplot does not accept two different variable calculations + mapping, so, here I am separating geom_line s and geom_point s.\n  \n#SF+Oakland\n  geom_line(data = citations_vs_warnings_per_city_per_month |&gt;\n              filter(city == \"San Francisco\" | city == \"Oakland\") |&gt;\n              group_by(month) |&gt;\n              summarise(sf_and_oakie = mean(citations_vs_warnings_ratio)),\n            aes(x = month, y = sf_and_oakie), size = 1, color = \"blue\") +\n  \n  geom_point(data = citations_vs_warnings_per_city_per_month |&gt;\n               filter(city == \"San Francisco\" | city == \"Oakland\") |&gt;\n               group_by(month) |&gt;\n               summarise(sf_and_oakie = mean(citations_vs_warnings_ratio)),\n             aes(x = month, y = sf_and_oakie), color = \"blue\", size = 3) +\n  \n#SD+Stockton\n  geom_line(data = citations_vs_warnings_per_city_per_month |&gt;\n              filter(city == \"San Diego\" | city == \"Stockton\") |&gt;\n              group_by(month) |&gt;\n              summarise(sd_and_stockton = mean(citations_vs_warnings_ratio)),\n            aes(x = month, y = sd_and_stockton), color = \"red\", size = 1) +\n  \n  geom_point(data = citations_vs_warnings_per_city_per_month |&gt;\n               filter(city == \"San Diego\" | city == \"Stockton\") |&gt;\n               group_by(month) |&gt;\n               summarise(sd_and_stockton = mean(citations_vs_warnings_ratio)),\n             aes(x = month, y = sd_and_stockton), color = \"red\", size = 3) +\n\n#Labeling Graph\n  labs(title = \"Avg. Citations vs. Warnings Ratio over Months for Bay Area vs. SD+Stockton\",\n       x = \"Month in 2014\",\n       y = \"Avg. Citations vs. Warnings Ratio\") +\n  scale_x_continuous(breaks = 1:12, labels = month.abb) + ylim(0, NA) + \n  theme_light() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 0.85))\n\n\n\n\n\n\n\n\nWith this graph, we can see in more detail the difference between Bay Area cities vs. SD and Stockton. However, this graph also makes us see if there is any correlation between time passing and punishment severity.\nWe see that both Bay Area cities and SD+Stockton peak in April or May, and then gradually go down in punishment severity. This is not clear or significant enough that we can say that this is not a result of just pure chance, but it is possible that something made punishments more severe in April-May 2014 and made them gradually decline. Possible, fully hypotethical explanations may include events going on around the country or new policing regulations in CA or the US around this time. Or, perhaps police become most comfortable hitting their citation quota around 4-5 months in and then slowly decline giving away citations, on average, if they need not fill that quota anymore or are making adequate progress. These are extremely hypotethical explanations to the very vague and non-significant relationship between months passing and our ratio, and cannot be validated without seeing other years except 2014 or without a permutation test or without a lot more data. Therefore, we can say that there is no clear connection between months passing and our tolerance/severity in traffic stops ratio.\n\n\nConclusion\nAll in all, we analyzed our data tables of Oakland, San Francisco, San Diego, and Stockton; CA from the Stanford Open Policing Project, cited below, for citations and warnings. We have defined a ratio where we take the ratio between citations and warnings. This ratio being high means more citations were issued for every case where the driver is being seen as in fault, therefore, telling us low tolerance exists. This ratio being low means less itations were issued for every case where the driver is being seen as in fault, therefore, telling us high tolerance exists. Although this is not a perfect metric, the stark difference between cities tells us something.\nWe have shown that a significant difference between cities exists for tolerance. More rural or less urban cities tend to have a lower citation vs. warning ratio or higher tolerance. This is supported by the data where Stockton, San Diego, and Bay Area cities are in that order both by in terms of urbanism/population and citation vs. warning ratio.\nWe also tried to come up with any correlation between months of the year determining tolerance; however, without more evidence, analysis, or data; it is not healthy to conclude that such a correlation does or does not exist.\n\n\nSource\nPierson, Emma, Camelia Simoiu, Jan Overgoor, Sam Corbett-Davies, Daniel Jenson, Amy Shoemaker, Vignesh Ramachandran, et al. 2020. “A Large-Scale Analysis of Racial Disparities in Police Stops Across the United States.” Nature Human Behaviour, 1–10."
  }
]